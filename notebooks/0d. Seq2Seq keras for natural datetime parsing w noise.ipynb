{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resources',\n",
       " 'synthetic_datestrings.csv',\n",
       " 'requirements.txt',\n",
       " '__pycache__',\n",
       " 'asd',\n",
       " 'test_use_layer_saved_model',\n",
       " 'README.md',\n",
       " 'train.py',\n",
       " 'test_use_layer',\n",
       " 'generate_trainset.py',\n",
       " '.git',\n",
       " 'tokenizer.json',\n",
       " 'keras_decoder',\n",
       " 'notebooks',\n",
       " 'savedmodel',\n",
       " 'src']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "tf.__version__\n",
    "\n",
    "import os\n",
    "os.listdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>date_string</th>\n",
       "      <th>decodable_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-12 10:23:07</td>\n",
       "      <td>2020-12-19 12:29:05</td>\n",
       "      <td>12/12/ - 19/12/2020</td>\n",
       "      <td>12/12/2020 - 19/12/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-01-15 10:21:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15 January 97</td>\n",
       "      <td>15/01/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-05-12 23:32:18</td>\n",
       "      <td>2016-02-09 10:17:53</td>\n",
       "      <td>12 May 12 - 09 February 16</td>\n",
       "      <td>12/05/2012 - 09/02/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1991-04-15 14:51:40</td>\n",
       "      <td>2013-12-10 03:45:10</td>\n",
       "      <td>15 Apr 91 - 10 Dec 13</td>\n",
       "      <td>15/04/1991 - 10/12/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-10-13 02:04:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13 October 13</td>\n",
       "      <td>13/10/2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            start_date             end_date                 date_string  \\\n",
       "0  2020-12-12 10:23:07  2020-12-19 12:29:05         12/12/ - 19/12/2020   \n",
       "1  1997-01-15 10:21:47                  NaN               15 January 97   \n",
       "2  2012-05-12 23:32:18  2016-02-09 10:17:53  12 May 12 - 09 February 16   \n",
       "3  1991-04-15 14:51:40  2013-12-10 03:45:10       15 Apr 91 - 10 Dec 13   \n",
       "4  2013-10-13 02:04:23                  NaN               13 October 13   \n",
       "\n",
       "          decodable_string  \n",
       "0  12/12/2020 - 19/12/2020  \n",
       "1               15/01/1997  \n",
       "2  12/05/2012 - 09/02/2016  \n",
       "3  15/04/1991 - 10/12/2013  \n",
       "4               13/10/2013  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../synthetic_datestrings.csv', index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character level Seq2Seq Keras\n",
    "https://keras.io/examples/nlp/lstm_seq2seq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!curl -O http://www.manythings.org/anki/fra-eng.zip\n",
    "# !!unzip fra-eng.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = \"fra.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare data\n",
    "1. Parse data file into `input_text` and `target_text`.\n",
    "```\n",
    "input_text\n",
    ">>> 'I own this car.'\n",
    "target_text\n",
    ">>> '\\tJe poss√®de cette voiture.\\n'\n",
    "```\n",
    "2. Generate character vocabulary in `list`s.\n",
    "3. Find max lenght of encoders and decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, string\n",
    "\n",
    "def apply_noisy_insertion(noiseless_string, noise):\n",
    "    assert noise < 1\n",
    "    if random.uniform(0,1) < noise:\n",
    "        inserted_letter = random.choice(string.ascii_letters)\n",
    "        insertion_position = np.random.randint(len(noiseless_string))\n",
    "        return noiseless_string[:insertion_position] + inserted_letter + noiseless_string[insertion_position:]\n",
    "    else:\n",
    "        return noiseless_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "# with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#     lines = f.read().split(\"\\n\")\n",
    "# for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "#     input_text, target_text, _ = line.split(\"\\t\")\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    input_text, target_text = apply_noisy_insertion(row.date_string, 0.05), row.decodable_string\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `input_token_index` and `target_token_index` store the dictionaries for the input and target characters. \n",
    "2. Input and output arrays are initialized in `encoder_input_data`, `decoder_input_data`, `decoder_target_data`.  \n",
    "\n",
    "Importantly, __teacher forcing__ is implemented as it forces the model to take in the correct label of the previous time step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t07/02/1996\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 281s 221ms/step - loss: 0.9693 - accuracy: 0.6613 - val_loss: 0.4887 - val_accuracy: 0.7898\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 262s 210ms/step - loss: 0.4641 - accuracy: 0.7989 - val_loss: 0.4196 - val_accuracy: 0.8174\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 282s 226ms/step - loss: 0.4152 - accuracy: 0.8203 - val_loss: 0.3841 - val_accuracy: 0.8322\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 270s 216ms/step - loss: 0.3815 - accuracy: 0.8343 - val_loss: 0.3571 - val_accuracy: 0.8441\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 274s 219ms/step - loss: 0.3436 - accuracy: 0.8527 - val_loss: 0.2946 - val_accuracy: 0.8792\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 273s 219ms/step - loss: 0.2830 - accuracy: 0.8853 - val_loss: 0.2482 - val_accuracy: 0.9006\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 265s 212ms/step - loss: 0.2287 - accuracy: 0.9092 - val_loss: 0.1713 - val_accuracy: 0.9340\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 266s 213ms/step - loss: 0.1689 - accuracy: 0.9342 - val_loss: 0.1296 - val_accuracy: 0.9507\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 261s 209ms/step - loss: 0.1309 - accuracy: 0.9497 - val_loss: 0.0950 - val_accuracy: 0.9658\n",
      "Epoch 10/10\n",
      "  63/1250 [>.............................] - ETA: 3:47 - loss: 0.0991 - accuracy: 0.9626"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=10,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training results w/o noise\n",
    "```\n",
    "Epoch 1/10\n",
    "1250/1250 [==============================] - 139s 109ms/step - loss: 0.9872 - accuracy: 0.6556 - val_loss: 0.4677 - val_accuracy: 0.8060\n",
    "Epoch 2/10\n",
    "1250/1250 [==============================] - 139s 111ms/step - loss: 0.4385 - accuracy: 0.8175 - val_loss: 0.3111 - val_accuracy: 0.8737\n",
    "Epoch 3/10\n",
    "1250/1250 [==============================] - 162s 130ms/step - loss: 0.2968 - accuracy: 0.8789 - val_loss: 0.2394 - val_accuracy: 0.9034\n",
    "Epoch 4/10\n",
    "1250/1250 [==============================] - 168s 135ms/step - loss: 0.2178 - accuracy: 0.9112 - val_loss: 0.1832 - val_accuracy: 0.9254\n",
    "Epoch 5/10\n",
    "1250/1250 [==============================] - 138s 110ms/step - loss: 0.1677 - accuracy: 0.9308 - val_loss: 0.1558 - val_accuracy: 0.9360\n",
    "Epoch 6/10\n",
    "1250/1250 [==============================] - 133s 107ms/step - loss: 0.1365 - accuracy: 0.9450 - val_loss: 0.0913 - val_accuracy: 0.9634\n",
    "Epoch 7/10\n",
    "1250/1250 [==============================] - 139s 111ms/step - loss: 0.0822 - accuracy: 0.9672 - val_loss: 0.0659 - val_accuracy: 0.9759\n",
    "Epoch 8/10\n",
    "1250/1250 [==============================] - 132s 106ms/step - loss: 0.0499 - accuracy: 0.9812 - val_loss: 0.0151 - val_accuracy: 0.9949\n",
    "Epoch 9/10\n",
    "1250/1250 [==============================] - 124s 100ms/step - loss: 0.0151 - accuracy: 0.9948 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
    "Epoch 10/10\n",
    "1250/1250 [==============================] - 123s 98ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s/assets\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save(\"s2s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 42) dtype=float32 (created by layer 'input_3')>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None, 42)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, None, 15)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 256), (None, 306176      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  278528      input_4[0][0]                    \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 15)     3855        lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 588,559\n",
      "Trainable params: 588,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling models\n",
    "# Restore the model and construct the encoder and decoder.\n",
    "model = keras.models.load_model(\"s2s\")\n",
    "\n",
    "encoder_inputs = model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,), name=\"hiddenstate_input\")\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,), name=\"cellstate_input\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: 28 September 97 - 21 May 98\n",
      "Decoded sentence: 28/09/1997 - 21/05/1998\n",
      "\n",
      "-\n",
      "Input sentence: 03-07-2004\n",
      "Decoded sentence: 07/03/2004\n",
      "\n",
      "-\n",
      "Input sentence: 03 September 13\n",
      "Decoded sentence: 03/09/2013\n",
      "\n",
      "-\n",
      "Input sentence: 23 aug 18 - 18 jul 19\n",
      "Decoded sentence: 23/08/2018 - 18/07/2019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [100,120,150, 200]:\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_texts[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 15) (1, 1, 15)\n",
      "[[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a323a1f8fc38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-a323a1f8fc38>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Sample a token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        print(target_seq.shape, output_tokens.shape)\n",
    "        print(target_seq)\n",
    "        raise\n",
    "        \n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence\n",
    "\n",
    "decoded_sentence = decode_sequence(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence, one_hot, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
